###############################################
### COMP 598 : Project #1                   ###
### ---------------------					###
### Authors:                                ###
###  + Nicolas Angelard-Gontier - 260532513 ###
###  + Genevieve Fried - 260564432          ###
###  + Charlie Bloomfield - 260520615       ###
###############################################

import parsingHelp
import datahacker

listofURLS = listofurls()
x,y,z,listoftitles = single_diffbotapi_call(listofURLS)


for url in listofURLS
	tfidf_new_inst = Tokenize(url,listoftitles)

	documents = tfidf_new_inst.basicParse(listoftitles)


    def create_document()
        """
        for line in open('mycorpus.txt'):
	        # assume there's one document per line, tokens separated by whitespace
	        yield dictionary.doc2bow(line.lower().split())
		"""

	    


	    	###here we want to check the semantic relevance of each title in 
	    	###our dictionary against the entire list of titles



